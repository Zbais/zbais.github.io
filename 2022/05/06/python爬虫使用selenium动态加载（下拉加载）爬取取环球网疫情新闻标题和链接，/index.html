<!DOCTYPE html>
<html lang="en" >
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
	<meta name="description" content="">
	<meta name="keywords" content="">
	<title>python爬虫使用selenium动态加载（下拉加载）爬取取环球网疫情新闻标题和链接， - Hexo</title>
    <link rel="alternate" href="" type="application/atom+xml"/>
	<link rel="shortcut icon" href=""/>
	
<link rel="stylesheet" href="/css/style.css">

	
<link rel="stylesheet" href="//netdna.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">

<meta name="generator" content="Hexo 6.1.0"></head>

<body>
	<div class="main-con">

        <div class="nav cl">
    <ul class="cl nav-list">
        
            <li>
                
                    <a href="/" class="">
                        <i class="fa fa-home"></i> 
                        <span>主页</span>
                    </a>
                
            </li>
        
            <li>
                
                    <a href="/archives/" class="">
                        <i class=" fa-"></i> 
                        <span>归档</span>
                    </a>
                
            </li>
        
            <li>
                
                    
                    <a href="javascript:void(0)" class="">
                    
                        <i class=" fa-"></i> 
                        <span>关于</span>
                        <span class="drop-flag fa fa-angle-down"></span>
                    </a>
                    <dl>
                        
                            <li>
                                <a href="/about" class="">
                                    <i class=" fa-"></i>
                                    <span>关于本站</span>
                                </a>
                            </li>
                        
                    </dl>
                
            </li>
        
    </ul>
    <ul class="cl nav-tool">
        
            <li>
                <a href="/github">
                    <i class="fa fa-github"></i>
                </a>
            </li>
        
            <li>
                <a href="/mail">
                    <i class="fa fa-envelope"></i>
                </a>
            </li>
        
            <li>
                <a href="/twitter">
                    <i class="fa fa-twitter"></i>
                </a>
            </li>
        
        
        <li>
            <a href="javascript:void(0)" class="nav-search-btn">
                <i class="fa fa-search"></i>
            </a>
        </li>
        
    </ul>
    <form action="//google.com/search" method="get" accept-charset="UTF-8" class="nav-search"><input type="search" name="q" class="nav-search-input" placeholder="search..."><input type="hidden" name="sitesearch" value="http://example.com"></form>
</div>

        <header class="top" id="fallEle" style="background-image: url(/imgs/head.jpg)">
    <i class="fa fa-bars" id="media-toggle" style="display: none"></i>
    <div class="top-info cl fadeToBottom">
        <h2 class="site-name"><a href="/">ZBAIS</a> <small id="type-data">This is ZBAIS&#39;s  blog</small></h2>
    </div>
</header>

        <div class="con-wrap fadeToTop">
    
    <section class="article-area">
    
        <article class="article">
    <div class="article-wrap">
        
            <h2 class="article-title cl">
                python爬虫使用selenium动态加载（下拉加载）爬取取环球网疫情新闻标题和链接，
            </h2>
        

        <ul class="article-extra" style="margin-bottom: 20px">
            
            <li class="article-time">
                2022-05-06
            </li>
            

            
                
            


        </ul>
        <div class="article-description">
            
            <p>当你爬数据的时候有没有遇到过向某个URL请求数据，响应回来的页面源码不全，明明在浏览器打开能看到，可到自己爬的时候就是看不到。其实是因为你爬取的页面是动态网页，很多数据是要加载才能渲染出来的。比如爬取环球网文章页面： <a target="_blank" rel="noopener" href="https://world.huanqiu.com/article">环球网</a>.</p>
<p><img src="https://img-blog.csdnimg.cn/20210331130357644.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hZTDM0MjMwMA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>这个时候通过request库就不太适合爬取动态网页了。目前主流是通过selenium去爬取。</p>
<p><strong>Selenium介绍：</strong></p>
<ol>
<li>Selenium是一个Web的自动化测试工具，最初是为网站自动化测试而开发的，Selenium 可以直接调用浏览器，它支持所有主流的浏览器（包括PhantomJS这些无界面的浏览器），可以接收指令，让浏览器自动加载页面，获取需要的数据，甚至页面截屏等。</li>
</ol>
<p>在使用selenium爬取数据之前必然要先下载selenium，找到你python下的Scripts文件夹，复制路径，用cmd打开，输入pip install selenium<br><img src="https://img-blog.csdnimg.cn/20210331131339409.png" alt="在这里插入图片描述"><br>然后就去下载浏览器驱动<br>首先查看浏览器版本，本文介绍Chrome，其他浏览器自行百度。 <a href="chrome://version/">点击查看Chrome版本</a><br> chromedriver与chrome各版本及下载地址： <a target="_blank" rel="noopener" href="https://blog.csdn.net/cz9025/article/details/70160273?utm_medium=distribute.pc_relevant_t0.none-task-blog-2~default~BlogCommendFromMachineLearnPai2~default-1.control&dist_request_id=1328761.728.16171688994638669&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2~default~BlogCommendFromMachineLearnPai2~default-1.control">具体看这位大佬的博客</a></p>
<hr>
<p><strong>接下来就展示一下如何使用selenium动态加载（下拉加载）获取环球网疫情新闻标题和链接，</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span>  requests, time, re                        <span class="comment">#</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup           <span class="comment">#使用bs4解析</span></span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver          <span class="comment">#自动化测试工具</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    url = <span class="string">&quot;https://world.huanqiu.com/article&quot;</span>       <span class="comment">#环球网文章url</span></span><br><span class="line">    headers = &#123;<span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36&quot;</span>&#125;</span><br><span class="line">    save_path = <span class="string">&quot;./news.txt&quot;</span>                        <span class="comment">#疫情文章和链接保存路径</span></span><br><span class="line">    get_data(url)                                   <span class="comment">#获取网页数据</span></span><br><span class="line">    parse_data(url)                                 <span class="comment">#解析提取所需数据</span></span><br><span class="line">    save_data(save_path,url)                        <span class="comment">#保存数据</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_data</span>(<span class="params">url</span>):</span><br><span class="line">    browser = webdriver.Chrome()                     <span class="comment">#创建Chrome浏览器对象，这会在电脑上在打开一个浏览器窗口</span></span><br><span class="line">    browser.get(url)                                 <span class="comment">#通过浏览器向服务器发送URL请求</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):                               </span><br><span class="line">        browser.execute_script(<span class="string">&quot;window.scrollTo(0,document.body.scrollHeight)&quot;</span>)         <span class="comment"># 将滚动条调整至页面底部循环三次</span></span><br><span class="line">        time.sleep(<span class="number">2</span>)</span><br><span class="line">    response = browser.page_source                      <span class="comment"># 获取页面源码</span></span><br><span class="line">    soup = BeautifulSoup(response, <span class="string">&#x27;lxml&#x27;</span>)              <span class="comment"># beautifulsoup 使用  lxml 解析</span></span><br><span class="line">    <span class="keyword">return</span> soup</span><br><span class="line"></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_data</span>(<span class="params">url</span>):</span><br><span class="line">    titles = []                                     <span class="comment">#爬取到的标题列表</span></span><br><span class="line">    hrefs = []                                      <span class="comment">#爬取到的标题链接列表</span></span><br><span class="line">    target_titles = []                              <span class="comment">#爬取到的疫情新闻标题列表</span></span><br><span class="line">    target_hrefs = []                               <span class="comment">#爬取到的疫情新闻标题链接列表</span></span><br><span class="line">    soup = get_data(url)</span><br><span class="line">    title_list = soup.select(<span class="string">&quot;.m-recommend-con ul li a div h4&quot;</span>)     <span class="comment">#调用soup的选择器方法找到标题位置，返回值为列表</span></span><br><span class="line">    href_list = soup.select(<span class="string">&quot;.m-recommend-con ul li a&quot;</span>)             <span class="comment">#调用soup的选择器方法找到标题链接位置，返回值为列表</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> title_list:</span><br><span class="line">        title = t.string</span><br><span class="line">        titles.append(title)                        <span class="comment">#添加至标题列表</span></span><br><span class="line">    <span class="keyword">for</span> h <span class="keyword">in</span> href_list:</span><br><span class="line">        href = h[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">        hrefs.append(href)                          <span class="comment">#添加至标题链接列表</span></span><br><span class="line">    i=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> title <span class="keyword">in</span> titles:</span><br><span class="line">        <span class="keyword">if</span>(((<span class="string">&#x27;新冠&#x27;</span> <span class="keyword">in</span> title)|(<span class="string">&#x27;疫苗&#x27;</span> <span class="keyword">in</span> title)|(<span class="string">&#x27;疫情&#x27;</span> <span class="keyword">in</span> title)|(<span class="string">&#x27;病毒&#x27;</span> <span class="keyword">in</span> title))):          <span class="comment">#通过关键字来获取疫情相关信息</span></span><br><span class="line">            target_titles.append(titles[i])                                                     <span class="comment">#添加至疫情新闻标题列表</span></span><br><span class="line">            target_hrefs.append(<span class="string">&quot;https://world.huanqiu.com&quot;</span>+hrefs[i])                           <span class="comment">#添加至疫情新闻标题链接列表，并通过字符串拼接成url</span></span><br><span class="line">        i = i+<span class="number">1</span>                             </span><br><span class="line">    <span class="keyword">return</span> target_titles,target_hrefs</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_data</span>(<span class="params">save_path,url</span>):</span><br><span class="line">    target_titles,target_hrefs = parse_data(url)</span><br><span class="line">    f = <span class="built_in">open</span>(save_path, <span class="string">&#x27;a&#x27;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>)                                              <span class="comment">#以追加的方式打开文件，如果不存在则创建，设置字符集为utf-8</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(target_titles)):                                             </span><br><span class="line">        f.write(target_titles[i])                                                           <span class="comment">#写入疫情新闻标题列表</span></span><br><span class="line">        f.write(<span class="string">&quot;\n&quot;</span>)                                                                       <span class="comment">#换行</span></span><br><span class="line">        f.write(target_hrefs[i])                                                            <span class="comment">#写入疫情新闻标题链接列表</span></span><br><span class="line">        f.write(<span class="string">&quot;\n\n&quot;</span>)</span><br><span class="line">    f.close()                                                                               <span class="comment">#关闭</span></span><br><span class="line">    <span class="keyword">pass</span>                                                                    </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
        </div>
        
        
        
        <div class="article-tags">
            <ul class="tags-list cl">
                
            </ul>
        </div>
        
        <div class="article-pagination cl">
        
            <div class="pagination-prev">
                <a href="/2022/05/06/idea-java-%E7%A8%8B%E5%BA%8F%E5%8C%85%C3%97%C3%97%C3%97-%C3%97%C3%97%C3%97%C3%97-%C3%97%C3%97%E4%B8%8D%E5%AD%98%E5%9C%A8%E3%80%82%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%EF%BC%8C/">idea java:程序包×××.××××.××不存在。解决方法，</a>
            </div>
        
        
            <div class="pagination-next">
                <a href="/2022/05/06/elasticsearch%E5%AE%89%E8%A3%85elasticsearch-analysis-ik%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%8F%92%E4%BB%B6%EF%BC%8C%E7%BD%91%E9%80%9F%E5%A4%AA%E6%85%A2%EF%BC%8C%E7%89%88%E6%9C%AC%E9%97%AE%E9%A2%98%E3%80%81%E5%AE%89%E8%A3%85%E5%A4%B1%E8%B4%A5%E8%A7%A3%E5%86%B3%E6%80%9D%E8%B7%AF/">Empty title</a>
            </div>
        
        </div>

        
    </div>
</article>

    </section>
    
<section class="tool-area">

    <div class="toolbar">
        

        
        <div class="widget-post widget" style="order: 1 ">
            <h2 class="widget-title"><i class="fa fa-file-text"></i> Recent articles</h2>
            <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2022/05/06/%E5%A4%A7%E5%AD%A6%E7%89%A9%E7%90%86-%E4%B9%A0%E9%A2%98%E5%88%86%E6%9E%90%E4%B8%8E%E8%A7%A3%E7%AD%94%EF%BC%88PDF%EF%BC%89/">大学物理 习题分析与解答（PDF）</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/05/06/%E8%A6%81%E6%B1%82%E6%8C%89%E7%85%A7%E8%80%83%E8%AF%95%E6%88%90%E7%BB%A9%E7%AD%89%E7%BA%A7%E8%BE%93%E5%87%BA%E7%99%BE%E5%88%86%E5%88%B6%E5%88%86%E6%95%B0%E6%AE%B5%EF%BC%8CA%E7%AD%89%E4%B8%BA85%E5%88%86%E4%BB%A5%E4%B8%8A%EF%BC%8CB%E7%AD%89%E4%B8%BA70-84%E5%88%86%EF%BC%8CC%E7%AD%89%E4%B8%BA60-69%E5%88%86%EF%BC%8CD%E7%AD%89%E4%B8%BA60%E5%88%86%E4%BB%A5%E4%B8%8B%E3%80%82%E6%88%90%E7%BB%A9%E7%AD%89%E7%BA%A7%E7%94%B1%E9%94%AE%E7%9B%98%E8%BE%93%E5%85%A5/">要求按照考试成绩等级输出百分制分数段，A等为85分以上，B等为70-84分，C等为60~69分，D等为60分以下。成绩等级由键盘输入</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/05/06/%E5%B7%A5%E7%A8%8B%E6%95%B0%E5%AD%A6%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%AC%AC%E5%85%AD%E7%89%88%E7%AD%94%E6%A1%88%E4%B8%8E%E8%A7%A3%E6%9E%90-%E3%80%8A%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E9%99%84%E5%86%8C%E5%AD%A6%E4%B9%A0%E8%BE%85%E5%AF%BC%E4%B8%8E%E4%B9%A0%E9%A2%98%E5%85%A8%E8%A7%A3%E3%80%8B/">工程数学线性代数第六版答案与解析,《线性代数附册学习辅导与习题全解》</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/05/06/%E9%80%9A%E8%BF%87python%E7%88%AC%E8%99%AB%E7%88%AC%E5%8F%96%E5%9B%BE%E7%89%87%EF%BC%8C%E5%B9%B6%E9%80%9A%E8%BF%87%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%8F%91%E9%80%81%E5%9B%BE%E7%89%87%E8%87%B3%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E7%BE%A4/">通过python爬虫爬取图片，并通过企业微信机器人发送图片至企业微信群</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/05/06/idea-java-%E7%A8%8B%E5%BA%8F%E5%8C%85%C3%97%C3%97%C3%97-%C3%97%C3%97%C3%97%C3%97-%C3%97%C3%97%E4%B8%8D%E5%AD%98%E5%9C%A8%E3%80%82%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%EF%BC%8C/">idea java:程序包×××.××××.××不存在。解决方法，</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/05/06/python%E7%88%AC%E8%99%AB%E4%BD%BF%E7%94%A8selenium%E5%8A%A8%E6%80%81%E5%8A%A0%E8%BD%BD%EF%BC%88%E4%B8%8B%E6%8B%89%E5%8A%A0%E8%BD%BD%EF%BC%89%E7%88%AC%E5%8F%96%E5%8F%96%E7%8E%AF%E7%90%83%E7%BD%91%E7%96%AB%E6%83%85%E6%96%B0%E9%97%BB%E6%A0%87%E9%A2%98%E5%92%8C%E9%93%BE%E6%8E%A5%EF%BC%8C/">python爬虫使用selenium动态加载（下拉加载）爬取取环球网疫情新闻标题和链接，</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/05/06/elasticsearch%E5%AE%89%E8%A3%85elasticsearch-analysis-ik%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%8F%92%E4%BB%B6%EF%BC%8C%E7%BD%91%E9%80%9F%E5%A4%AA%E6%85%A2%EF%BC%8C%E7%89%88%E6%9C%AC%E9%97%AE%E9%A2%98%E3%80%81%E5%AE%89%E8%A3%85%E5%A4%B1%E8%B4%A5%E8%A7%A3%E5%86%B3%E6%80%9D%E8%B7%AF/">elasticsearch安装elasticsearch-analysis-ik中文分词插件，网速太慢，版本问题、安装失败解决思路</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/05/05/hello-world/">hello-world</a></li></ul>
        </div>
        

        
        <div class="widget-tags widget" style="order: 2 ">
            <h2 class="widget-title"><i class="fa fa-tags"></i> Tag</h2>
            
        </div>
        

        
        <div class="widget-categories widget" style="order: 3 ">
            <h2 class="widget-title"><i class="fa fa-folder-open"></i> Categories</h2>
            
        </div>
        

    </div>
</section>
</div>

    
        <footer class="footer">
	<p class="footer-intro">
		
		@2022 Hexo.
	</p>
	<p class="footer-intro">
			Powered By <a href="https://hexo.io/zh-cn/" target="_blank">hexo</a>
			theme <a href="https://github.com/iengu/hexo-theme-mokusei" target="_blank">mokusei</a> by <a href="https://www.iengu.com" target="blank">iengu</a>
	</p>
</footer>




        <div class="extend-tools" id="extend-tools" style="display: none;">
    <ul>
        <li class="tools-returnTop" title="Back to top"><i class="fa fa-angle-double-up"></i></li>
    </ul>
</div>

	</div>

	
<script src="/js/org/jquery.min.js"></script>

    
<script src="/js/extend.js"></script>

</body>
</html>